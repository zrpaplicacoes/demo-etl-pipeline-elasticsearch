<!DOCTYPE html>
<html lang="en">
<head>
    
    <meta charset="utf-8">
    <title>src/destination.js - zrp meet#2: ETL demo</title>
    
    <meta name="description" content="This application is a demo app that uses node streams to extract, transform and push data from two sources, openflights and a gzip csv file containing recipes from kaggle on ElasticSearch for querying and analysis, implementing a simple ETL pipeline." />
    
    
    
    <script src="scripts/prettify/prettify.js"></script>
    <script src="scripts/prettify/lang-css.js"></script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc.css">
    <script src="scripts/nav.js" defer></script>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>

<input type="checkbox" id="nav-trigger" class="nav-trigger" />
<label for="nav-trigger" class="navicon-button x">
  <div class="navicon"></div>
</label>

<label for="nav-trigger" class="overlay"></label>

<nav >
    
    <input type="text" id="nav-search" placeholder="Search" />
    
    <h2><a href="index.html">Home</a></h2><h2><a href="https://github.com/zrpaplicacoes/demo-etl-pipeline-elasticsearch" target="_blank" class="menu-item" id="repository" >GitHub</a></h2><h3>Modules</h3><ul><li><a href="module-core.html">core</a></li><li><a href="module-core_constants.html">core/constants</a></li><li><a href="module-core_destination.html">core/destination</a><ul class='methods'><li data-type='method'><a href="module-core_destination.html#~generateBulkRequestBody">generateBulkRequestBody</a></li><li data-type='method'><a href="module-core_destination.html#~generateRequestBody">generateRequestBody</a></li><li data-type='method'><a href="module-core_destination.html#~logFailure">logFailure</a></li><li data-type='method'><a href="module-core_destination.html#~post">post</a></li><li data-type='method'><a href="module-core_destination.html#~toElasticSearch">toElasticSearch</a></li></ul></li><li><a href="module-core_source.html">core/source</a><ul class='methods'><li data-type='method'><a href="module-core_source.html#~download">download</a></li></ul></li><li><a href="module-core_transform.html">core/transform</a><ul class='methods'><li data-type='method'><a href="module-core_transform.html#~addTimestamp">addTimestamp</a></li><li data-type='method'><a href="module-core_transform.html#~calories">calories</a></li><li data-type='method'><a href="module-core_transform.html#~stringify">stringify</a></li><li data-type='method'><a href="module-core_transform.html#~toAirtravelRoute">toAirtravelRoute</a></li></ul></li><li><a href="module-lib.html">lib</a></li><li><a href="module-lib_environment.html">lib/environment</a><ul class='members'><li data-type='member'><a href="module-lib_environment.html#.defaultMeta">defaultMeta</a></li><li data-type='member'><a href="module-lib_environment.html#.isDevelopment">isDevelopment</a></li><li data-type='member'><a href="module-lib_environment.html#.isProd">isProd</a></li><li data-type='member'><a href="module-lib_environment.html#.serviceName">serviceName</a></li></ul></li><li><a href="module-lib_logger.html">lib/logger</a><ul class='members'><li data-type='member'><a href="module-lib_logger.html#.logger">logger</a></li><li data-type='member'><a href="module-lib_logger.html#.logLevel">logLevel</a></li></ul></li></ul><h3>Global</h3><ul><li><a href="global.html#example01">example01</a></li><li><a href="global.html#example02">example02</a></li><li><a href="global.html#openflightDemo">openflightDemo</a></li><li><a href="global.html#recipesDemo">recipesDemo</a></li></ul>
</nav>

<div id="main">
    
    <h1 class="page-title">src/destination.js</h1>
    

    



    
    <section>
        <article>
            <pre class="prettyprint source linenums"><code>/**
 * Implement stream functionally
 * related to stream.Writable
 *
 * @module core/destination
 */

// Dependencies
const AWS = require("aws-sdk")
const parallel = require("parallel-stream")

// Lib
const { logger } = require("../lib")
const { concurrency } = require("./constants")

// Globals
const esDomain = process.env.ES_DOMAIN

if (!esDomain) {
  throw `
    An ElasticSearch domain is required to run this application.
    Modify your .env file to include an envvar ES_DOMAIN;
  `
}

// Log failed / success ES requests
const logFailedResponses = process.env.LOG_FAILED_ES_RESPONSES === "true"
const logSuccessResponses = process.env.LOG_SUCCESS_ES_RESPONSES === "true"

/**
 * Generate a single request body
 */
function generateRequestBody(indexPrefix, type, data) {
  const { timestamp } = data
  const t = new Date(timestamp ? timestamp : Date.now())

  // Format indexes name as
  // prefix-YYYY.MM.DD
  const indexName = [
    indexPrefix + t.getUTCFullYear(), // year
    ("0" + (t.getUTCMonth() + 1)).slice(-2), // month
    ("0" + t.getUTCDate()).slice(-2), // day
  ].join(".")

  // Define source of data
  const source = {
    ...data,
  }

  // Create action
  const action = {
    index: {
      _index: indexName,
      _type: type,
    },
  }

  return [JSON.stringify(action), JSON.stringify(source)].join("\n") + "\n"
}

/**
 * Generates the bulk request body
 * using the routes array
 *
 * @param {string} indexPrefix - The index which this document belongs
 * @param {type} type - The document type
 * @param {any[]} routes
 */
function generateBulkRequestBody(indexPrefix, type, data) {
  let bulkRequestBody = ""

  if (Array.isArray(data)) {
    data.forEach(
      d => (bulkRequestBody += generateRequestBody(indexPrefix, type, d)),
    )
  } else {
    bulkRequestBody += generateRequestBody(indexPrefix, type, data)
  }

  return bulkRequestBody
}

/**
 * Post data to ES /_bulk
 *
 * @param {*} body
 * @param {*} callback
 */
function post(body, callback) {
  const endpoint = new AWS.Endpoint(esDomain)
  const request = new AWS.HttpRequest(endpoint, "us-east-1")

  request.method = "POST"
  request.path = "/_bulk"
  request.body = body

  request.headers["Host"] = esDomain
  request.headers["Content-Type"] = "application/json"
  request.headers["Content-Length"] = Buffer.byteLength(request.body)

  const credentials = new AWS.EnvironmentCredentials("AWS")
  const signer = new AWS.Signers.V4(request, "es")

  signer.addAuthorization(credentials, new Date())

  const client = new AWS.HttpClient()

  client.handleRequest(
    request,
    null,
    function(response) {
      var responseBody = ""

      response.on("data", function(chunk) {
        responseBody += chunk
      })

      response.on("end", function() {
        var info = JSON.parse(responseBody)
        var failedItems
        var success
        var error

        if (response.statusCode >= 200 &amp;&amp; response.statusCode &lt; 299) {
          failedItems = info.items.filter(function(x) {
            return x.index.status >= 300
          })

          success = {
            attemptedItems: info.items.length,
            successfulItems: info.items.length - failedItems.length,
            failedItems: failedItems.length,
          }
        }

        if (response.statusCode !== 200 || info.errors === true) {
          // prevents logging of failed entries, but allows logging
          // of other errors such as access restrictions
          delete info.items
          error = {
            statusCode: response.statusCode,
            responseBody: info,
          }
        }

        callback(error, success, response.statusCode, failedItems)
      })
    },
    function(error) {
      logger.error("Client could not handle request to ES", { error })
      callback(error)
    },
  )
}

/**
 * Log failed items
 *
 * @param {*} error
 * @param {*} failedItems
 */
function logFailure(error, failedItems) {
  if (logFailedResponses) {
    logger.error("Error: " + JSON.stringify(error, null, 2))

    if (failedItems &amp;&amp; failedItems.length > 0) {
      logger.error("Failed Items: " + JSON.stringify(failedItems, null, 2))
    }
  }
}

/**
 * A write stream that writes incoming
 * data to ElasticSearch using POST /_bulk
 *
 */
function toElasticSearch({ indexPrefix, type }) {
  const queue = []

  const writable = new parallel.writable(
    (chunk, _encoding, done) => {
      let body

      if (Array.isArray(chunk)) {
        body = generateBulkRequestBody(indexPrefix, type, chunk)
      } else {
        queue.push(chunk)

        if (queue.length >= 500) {
          body = generateBulkRequestBody(indexPrefix, type, queue.splice(0))
        }
      }

      if (!body) {
        done(null, null)
        return
      }

      post(body, (error, success, _, failedItems) => {
        if (error) {
          logFailure(error, failedItems)
        } else {
          if (logSuccessResponses) {
            logger.info(
              `Indexed ${success.successfulItems}/${success.attemptedItems} (${success.failedItems} errors)`,
            )
          }
        }

        done(null, null)
      })
    },
    { objectMode: true, concurrency },
  )

  return writable
}

module.exports = {
  toElasticSearch,
}
</code></pre>
        </article>
    </section>




    
    
</div>

<br class="clear">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.6.3</a> on Thu Dec 05 2019 19:41:32 GMT-0200 (Brasilia Summer Time) using the <a href="https://github.com/clenemt/docdash">docdash</a> theme.
</footer>

<script>prettyPrint();</script>
<script src="scripts/polyfill.js"></script>
<script src="scripts/linenumber.js"></script>

<script src="scripts/search.js" defer></script>



</body>
</html>
